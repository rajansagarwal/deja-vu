{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwLheD5DVKAc",
        "outputId": "3b46b8c3-4df3-4745-ec0d-aeee003a65e0"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers umap umap-learn langchain cohere faiss-cpu textract moviepy moviepy google-cloud-speech pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8g0XL4ClbP3"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless ipywidgets pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvuxOj9kxCje"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "tiny_model = whisper.load_model(\"tiny.en\")\n",
        "base_model = whisper.load_model(\"base.en\")\n",
        "small_model = whisper.load_model(\"small.en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt1E3jA4VuhD",
        "outputId": "78a79245-e705-473f-bf3f-e6ec8180eea6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "input_video_file = \"/content/test.avi\"\n",
        "output_folder = \"/content/video_fragments/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "def split_video_into_fragments(input_video_file, fragment_duration=10):\n",
        "    clip = VideoFileClip(input_video_file)\n",
        "    duration = int(clip.duration)\n",
        "\n",
        "    fragment_start = 0\n",
        "    fragment_end = fragment_duration\n",
        "\n",
        "    fragment_num = 1\n",
        "\n",
        "    while fragment_end <= duration:\n",
        "        output_file = os.path.join(output_folder, f\"fragment_{fragment_num}.avi\")\n",
        "        ffmpeg_extract_subclip(input_video_file, fragment_start, fragment_end, targetname=output_file)\n",
        "\n",
        "        fragment_start += fragment_duration\n",
        "        fragment_end += fragment_duration\n",
        "        fragment_num += 1\n",
        "\n",
        "split_video_into_fragments(input_video_file, fragment_duration=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo3gaGGujfAh"
      },
      "outputs": [],
      "source": [
        "transcriptions = []\n",
        "file_names = []\n",
        "\n",
        "for i in range(1, 8):\n",
        "    video_file = f'fragment_{i}.avi'\n",
        "    video_path = \"video_fragments/\" + video_file\n",
        "    audio_path = \"video_fragments/\" + video_file[:-4] + \".wav\"\n",
        "\n",
        "    y, sr = librosa.load(video_path, sr=16000)\n",
        "    sf.write(audio_path, y, sr)\n",
        "\n",
        "    result = tiny_model.transcribe(audio_path)\n",
        "    text = result[\"text\"].strip()\n",
        "    text = text.replace(\". \", \".\\n\\n\")\n",
        "\n",
        "    text_file = video_file[:-4] + \".txt\"\n",
        "    text_path = \"video_fragments/\" + text_file\n",
        "    with open(text_path, \"w\") as f:\n",
        "        f.write(text)\n",
        "    transcriptions.append(text)\n",
        "    file_names.append(video_file)\n",
        "\n",
        "df = pd.DataFrame({'File Name': file_names, 'Transcription': transcriptions})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "kxQUv-Qmqh0X",
        "outputId": "5920636f-440f-48a8-ad6c-1c91ae30b7d4"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFZ0fvrvS8Se",
        "outputId": "a8d9b58d-2be5-431e-a727-f616a625b4b3"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLwJzYPLTKUD"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn\n",
        "import umap.umap_ as umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmyIEkCKhJBh"
      },
      "outputs": [],
      "source": [
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdmFkVhhh6g2"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbJE8KtipRPW"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import CohereEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVyBJiH3jsrH",
        "outputId": "b367b44e-c1a5-48d5-da26-d9df14d2c445"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import seaborn as sns\n",
        "from scipy import spatial\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "map = {}\n",
        "with open('df.csv', newline='') as csvfile:\n",
        "    fragments = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
        "    next(fragments)\n",
        "    for row in fragments:\n",
        "        id, filename, transcription = row\n",
        "        map[transcription] = filename\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "transcriptions = list(map.keys())\n",
        "embeddings = model.encode(transcriptions)\n",
        "\n",
        "embeddings = {map[paragraph]: embedding for paragraph, embedding in zip(transcriptions, embeddings)}\n",
        "embeddings.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBAHDmMFqLu1"
      },
      "outputs": [],
      "source": [
        "import umap.umap_ as umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rlr2w-4kgjb",
        "outputId": "5b9f5032-19d2-43bc-c2ce-19dc353d91a3"
      },
      "outputs": [],
      "source": [
        "reducer = umap.UMAP()\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(list(embeddings.values()))\n",
        "reduced_data = reducer.fit_transform(scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwmKHI1PqTFV",
        "outputId": "17974a87-aa8d-4502-cda9-d182358af907"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "user_input = input(\"Enter a text for semantic search: \")\n",
        "user_input_embedding = model.encode(user_input)\n",
        "\n",
        "similarities = cosine_similarity([user_input_embedding], list(embeddings.values()))\n",
        "most_similar_indices = similarities.argsort()[0][::-1]\n",
        "\n",
        "print(\"\\nMost similar:\")\n",
        "for idx in most_similar_indices:\n",
        "    info = df.iloc[idx]\n",
        "    print(f\"Transcription:\", info, \"Similarity:\", similarities[0][idx].round(4))\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
